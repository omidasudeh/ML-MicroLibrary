{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import copy as cp\n",
    "import sys\n",
    "import pickle\n",
    "test_df = pd.read_csv(\"./bank/test.csv\", header=None)\n",
    "m_test = len(test_df)\n",
    "\n",
    "train_df = pd.read_csv(\"./bank/train.csv\", header=None)\n",
    "m_train = len(train_df)\n",
    "\n",
    "# train_df = pd.read_csv(\"./bank/sample1.csv\", header=None)\n",
    "# m_train = len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing numerical attribute: age threashold: 38.0\n",
      "preprocessing numerical attribute: balance threashold: 452.5\n",
      "preprocessing numerical attribute: day threashold: 16.0\n",
      "preprocessing numerical attribute: duration threashold: 180.0\n",
      "preprocessing numerical attribute: campaign threashold: 2.0\n",
      "preprocessing numerical attribute: pdays threashold: -1.0\n",
      "preprocessing numerical attribute: previous threashold: 0.0\n",
      "preprocessing numerical attribute: age threashold: 39.0\n",
      "preprocessing numerical attribute: balance threashold: 454.0\n",
      "preprocessing numerical attribute: day threashold: 16.0\n",
      "preprocessing numerical attribute: duration threashold: 179.0\n",
      "preprocessing numerical attribute: campaign threashold: 2.0\n",
      "preprocessing numerical attribute: pdays threashold: -1.0\n",
      "preprocessing numerical attribute: previous threashold: 0.0\n"
     ]
    }
   ],
   "source": [
    "attrib_name = {0:\"age\", 1:\"job\",2:\"marital\",3:\"education\",4:\"default\",5:\"balance\", 6:\"housing\",7:\"loan\",8:\"contact\",9:\"day\",10:\"month\",11:\"duration\",12:\"campaign\",13:\"pdays\",14:\"previous\",15:\"poutcome\"}\n",
    "label_values = [1, -1]\n",
    "\n",
    "categorical_attrib_values = { \"job\":     [\"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\", \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\"],\\\n",
    "                 \"marital\":  [\"married\",\"divorced\",\"single\"],\\\n",
    "                 \"education\":[\"unknown\",\"secondary\",\"primary\",\"tertiary\"],\\\n",
    "                 \"default\":  [\"yes\",\"no\"],\\\n",
    "                 \"housing\":  [\"yes\",\"no\"],\\\n",
    "                 \"loan\":     [\"yes\",\"no\"],\\\n",
    "                 \"contact\":  [\"unknown\",\"telephone\",\"cellular\"],\\\n",
    "                 \"month\":    [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"],\\\n",
    "                 \"poutcome\": [\"unknown\",\"other\",\"failure\",\"success\"]\n",
    "                }\n",
    "def convert_numerical_to_binary(df, Label_col_index):\n",
    "    for col_idx in range(Label_col_index):\n",
    "        if attrib_name[col_idx] not in categorical_attrib_values:\n",
    "            df[col_idx] = pd.to_numeric(df[col_idx], errors='coerce')\n",
    "            threashold = df[col_idx].median()\n",
    "            print(\"preprocessing numerical attribute:\", attrib_name[col_idx], \"threashold:\", threashold)\n",
    "            df[col_idx] = df[col_idx].apply(lambda x: 0 if int(x) <= threashold else 1)\n",
    "\n",
    "######## convert the numerical to binary\n",
    "train_df_processed = train_df\n",
    "test_df_processed = test_df\n",
    "convert_numerical_to_binary(train_df_processed, 16)\n",
    "convert_numerical_to_binary(test_df_processed, 16)\n",
    "\n",
    "######## convert label: yes->+1 no-> -1\n",
    "train_df_processed[16] = train_df_processed[16].apply(lambda x: -1 if x=='no' else 1)\n",
    "test_df_processed[16] = test_df_processed[16].apply(lambda x: -1 if x=='no' else 1)\n",
    "\n",
    "######## the the initial weights as a column to the dataframe\n",
    "Dtrain = [1/m_train] * m_train\n",
    "train_df_processed[17] = Dtrain\n",
    "# print(train_df_processed)\n",
    "Dtest  = [1/m_test]  * m_test\n",
    "test_df_processed[17] = Dtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gain functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the information gain\n",
    "def entropy_gain(S,Label_col_index, attrib_idx): \n",
    "    H_S = S.groupby(Label_col_index)[Label_col_index + 1]\\\n",
    "    .apply(lambda x: (x.sum())*np.log2(x.sum()))\\\n",
    "    .sum()*-1\n",
    "    \n",
    "#     val0 = S.groupby([attrib_idx,Label_col_index])[Label_col_index].count()\n",
    "    val0 = S.groupby([attrib_idx,Label_col_index])[Label_col_index+1].sum()\n",
    "    val1 = S.groupby([attrib_idx])[Label_col_index+1].sum()\n",
    "#     print(val0)\n",
    "#     print(val1)\n",
    "    val2 = val0/val1\n",
    "    val3 = val2.apply(lambda x: x*math.log2(x)).reset_index(name='plog2p')\n",
    "    val4 = val3.groupby([attrib_idx])[\"plog2p\"].sum()*-1\n",
    "    val5 = S.groupby([attrib_idx])[attrib_idx].apply(lambda x: x.count()/S.shape[0])\n",
    "\n",
    "    Expected_H_Sv = (val4*val5).sum()\n",
    "\n",
    "#     print(\"H_S:\",H_S, \"Expected_H_Sv\",Expected_H_Sv, \"gain:\",H_S - Expected_H_Sv)\n",
    "    return H_S - Expected_H_Sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# id3 and prediction fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# returns the label that has the max weight\n",
    "# S: set of examples\n",
    "def select_label_with_max_weight_sum(S, Label_col_index):\n",
    "    return S.groupby([Label_col_index])[Label_col_index+1].sum().idxmax()\n",
    "    \n",
    "# returns the column index of the best splitter attribute\n",
    "# S: set of examples\n",
    "# Attributes: list of attributes to be evaluated\n",
    "# splitter_algorithm: the splitter algorithm, can be one of the 3 values (\"ME\":Majority Error, \"GI\":Gini Index, \"EN\":Entropy)\n",
    "def Best_spliter_attribute(S, Attributes, Label_col_index, splitter_algorithm):\n",
    "    if len(Attributes) < 2:\n",
    "        return Attributes[0]\n",
    "    best_gain = 0\n",
    "    best_attribute = Attributes[0] #\n",
    "    for v in Attributes:\n",
    "        if v != Label_col_index:\n",
    "            gain_v = 0\n",
    "            if splitter_algorithm == \"EN\":\n",
    "                gain_v = entropy_gain(S,Label_col_index, v)\n",
    "#                 print(\"attrib:\",attrib_name[v], \"gain:\",gain_v)\n",
    "            else:\n",
    "                assert False, \"Unknown splitter_algorithm:\" + splitter_algorithm + \"!!!\"\n",
    "            if gain_v > best_gain:\n",
    "                best_gain = gain_v\n",
    "                best_attribute = v\n",
    "#     print(\"best is:\",best_attribute, \"GAIN:\",best_gain)\n",
    "    return best_attribute\n",
    "\n",
    "def numeric_attrib_value(S, attrib_col_idx, numeric_value):\n",
    "    threashold = S[attrib_col_idx].median()\n",
    "    return numeric_value >= threashold   \n",
    "\n",
    "def predict(root, entry, Label_col_index):\n",
    "    example = {} \n",
    "    for i in range(Label_col_index):\n",
    "        example[attrib_name[i]] = entry[i]\n",
    "    return predict_helper(root, example)\n",
    "\n",
    "def predict_helper(root, example):\n",
    "    if isinstance(root, list): # if attrib-node\n",
    "        root_attrib_name = root[0]\n",
    "    else:\n",
    "        return root\n",
    "    example_attrib_val = example[root_attrib_name]\n",
    "    if isinstance(root[1][example_attrib_val], list): # if attrib-node\n",
    "        return predict_helper(root[1][example_attrib_val], example)\n",
    "    else: # if leaf node\n",
    "        return root[1][example_attrib_val]\n",
    "    \n",
    "def predict_dataset(S, root, Label_col_index):\n",
    "    all = 0\n",
    "    correct = 0\n",
    "    hx = []\n",
    "    for idx, row in S.iterrows():\n",
    "        all += 1\n",
    "        gold_label = row[Label_col_index]\n",
    "        predicted_label = predict(root, row, Label_col_index)\n",
    "        hx.append(predicted_label)\n",
    "        if predicted_label == gold_label:\n",
    "            correct +=1\n",
    "    return correct / all , hx # accuracy, set of predictions\n",
    "        \n",
    "# ##############              ID3 implementation:\n",
    "# Input:\n",
    "# S: the set of Examples\n",
    "# Attributes: the set of measured attributes\n",
    "# Label_col_index: column index of the target attribute (the prediction)\n",
    "# max_tree_level: bounds the height of the tree\n",
    "# splitter_algorithm: can be one of the 3 values (\"ME\":Majority Error, \"GI\":Gini Index, \"EN\":Entropy)\n",
    "def ID3(S, Attributes, Label_col_index, max_tree_level, splitter_algorithm):\n",
    "    if(max_tree_level == 0):                                                            # if at max level\n",
    "#         print(\"max_tree_level reached\")\n",
    "        return select_label_with_max_weight_sum(S, Label_col_index)\n",
    "    elif S[Label_col_index].nunique() == 1:                                             # if all examples have same label:   \n",
    "#         print(\"Label_col_index unique\")\n",
    "        return select_label_with_max_weight_sum(S, Label_col_index)\n",
    "    elif len(Attributes) == 0:                                                          # if Attributes empty\n",
    "#         print(\"Attributes\")\n",
    "        return select_label_with_max_weight_sum(S, Label_col_index)\n",
    "    else:\n",
    "        # 1. Create a Root node for tree\n",
    "        Root = [] # each \"attribute node\" is a list s.t. \n",
    "                                                    # 1st element = string attribute name\n",
    "                                                    # 2nd element = dictionary children;\n",
    "                                                            # key = each possible attribute value v\n",
    "                                                            # value = an \"attribute node\" list;  or a string label for leaf nodes\n",
    "        # 2. A = attribute in Attributes that best splits S\n",
    "        A = Best_spliter_attribute(S, Attributes, Label_col_index, splitter_algorithm)\n",
    "#         print(\"best is:\",attrib_name[A])\n",
    "        Root.append(attrib_name[A]) # 1st element = string attribute name\n",
    "        Root.append({})             # 2nd element = dictionary children;\n",
    "        # 3. for each possible value v of that A can take:\n",
    "        attribute_values=[]\n",
    "        if(attrib_name[A] in categorical_attrib_values):\n",
    "            attribute_values = categorical_attrib_values[attrib_name[A]]\n",
    "        else: # o.w. it is numerical \n",
    "            attribute_values = [0,1]\n",
    "        for v in attribute_values:\n",
    "            # 1. Add a new tree branch corresponding to A=v\n",
    "            # 2. Let Sv be the subset of examples in S with A=v\n",
    "            Sv = S.loc[S[A] == v]\n",
    "            if len(Sv) == 0: # if Sv is empty\n",
    "#                 print(\"Sv is empty\")\n",
    "                Root[1][v] = select_label_with_max_weight_sum(S, Label_col_index) # string label\n",
    "            else:\n",
    "                Attrib_minus_A = Attributes\n",
    "                if len(Attrib_minus_A) > 0 and A in Attrib_minus_A:\n",
    "                    Attrib_minus_A.remove(A)\n",
    "                Root[1][v] = ID3(Sv, Attrib_minus_A,Label_col_index, max_tree_level-1,splitter_algorithm) # an \"attribute node\" list;\n",
    "        return Root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######\n",
      "['duration', {0: ['month', {'jan': ['job', {'admin.': -1, 'unknown': -1, 'unemployed': -1, 'management': ['age', {0: -1, 1: ['marital', {'married': -1, 'divorced': -1, 'single': 1}]}], 'housemaid': -1, 'entrepreneur': -1, 'student': -1, 'blue-collar': -1, 'self-employed': -1, 'retired': -1, 'technician': -1, 'services': -1}], 'feb': ['education', {'unknown': ['default', {'yes': -1, 'no': ['balance', {0: -1, 1: ['housing', {'yes': -1, 'no': 1}]}]}], 'secondary': ['poutcome', {'unknown': -1, 'other': -1, 'failure': -1, 'success': ['loan', {'yes': 1, 'no': -1}]}], 'primary': ['contact', {'unknown': -1, 'telephone': -1, 'cellular': ['day', {0: ['campaign', {0: -1, 1: ['pdays', {0: ['previous', {0: -1, 1: -1}], 1: -1}]}], 1: -1}]}], 'tertiary': -1}], 'mar': -1, 'apr': -1, 'may': -1, 'jun': -1, 'jul': -1, 'aug': -1, 'sep': -1, 'oct': -1, 'nov': -1, 'dec': -1}], 1: -1}]\n",
      "bagged_trees/3.out train_accuracy: 0.881 test_accuracy: 0.8738\n"
     ]
    }
   ],
   "source": [
    "# # generate a bootstrap tree \n",
    "Attributes = [0,1,2,3,4,5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "train_df_sample = train_df_processed.sample(m_train, replace=True)\n",
    "tree = ID3(train_df_sample, Attributes,16,16, \"EN\")\n",
    "\n",
    "print(\"#######\")\n",
    "print(tree)\n",
    "\n",
    "tree_ID = int(sys.argv[1])\n",
    "import pickle\n",
    "filename = \"bagged_trees/\"+str(tree_ID)+\".out\"\n",
    "\n",
    "# # compute the train and test predictions and accuracies\n",
    "train_accuracy, hx_train = predict_dataset(train_df_processed, tree,16)\n",
    "test_accuracy , hx_test  =  predict_dataset(test_df_processed, tree,16)\n",
    "\n",
    "print(filename, \"train_accuracy:\",train_accuracy,\"test_accuracy:\",test_accuracy)\n",
    "\n",
    "# # save them in the file\n",
    "output_packet = [train_accuracy,test_accuracy, hx_train,hx_test]\n",
    "with open(filename, 'wb') as handle:\n",
    "    pickle.dump(output_packet, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import copy as cp\n",
    "test_df = pd.read_csv(\"./bank/test.csv\", header=None)\n",
    "m_test = len(test_df)\n",
    "\n",
    "# train_df = pd.read_csv(\"./bank/train.csv\", header=None)\n",
    "# m_train = len(train_df)\n",
    "\n",
    "train_df = pd.read_csv(\"./bank/sample1.csv\", header=None)\n",
    "m_train = len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_sample = train_df.sample(10)\n",
    "# print(train_df_sample)\n",
    "# train_df_sample.to_csv(\"sample.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing numerical attribute: age threashold: 38.0\n",
      "preprocessing numerical attribute: balance threashold: 309.0\n",
      "preprocessing numerical attribute: day threashold: 14.5\n",
      "preprocessing numerical attribute: duration threashold: 273.0\n",
      "preprocessing numerical attribute: campaign threashold: 2.0\n",
      "preprocessing numerical attribute: pdays threashold: -1.0\n",
      "preprocessing numerical attribute: previous threashold: 0.0\n",
      "preprocessing numerical attribute: age threashold: 39.0\n",
      "preprocessing numerical attribute: balance threashold: 454.0\n",
      "preprocessing numerical attribute: day threashold: 16.0\n",
      "preprocessing numerical attribute: duration threashold: 179.0\n",
      "preprocessing numerical attribute: campaign threashold: 2.0\n",
      "preprocessing numerical attribute: pdays threashold: -1.0\n",
      "preprocessing numerical attribute: previous threashold: 0.0\n",
      "   0            1         2          3   4   5    6    7         8   9    10  \\\n",
      "0   1       admin.   married  secondary  no   0  yes  yes   unknown   0  jun   \n",
      "1   1   management   married  secondary  no   1   no   no   unknown   1  jun   \n",
      "2   1       admin.   married   tertiary  no   1   no   no  cellular   1  jul   \n",
      "3   0   technician    single  secondary  no   0  yes  yes   unknown   0  may   \n",
      "4   0     services   married  secondary  no   0  yes   no  cellular   1  jul   \n",
      "5   1  blue-collar  divorced  secondary  no   1  yes   no   unknown   1  may   \n",
      "6   0   management    single   tertiary  no   1   no   no  cellular   0  aug   \n",
      "7   0  blue-collar   married  secondary  no   0  yes   no  cellular   1  jul   \n",
      "8   0       admin.   married  secondary  no   0   no   no  cellular   0  aug   \n",
      "9   1      retired   married   tertiary  no   1   no   no   unknown   0  may   \n",
      "\n",
      "   11  12  13  14       15  16   17  \n",
      "0   1   1   0   0  unknown  -1  0.1  \n",
      "1   0   0   0   0  unknown  -1  0.1  \n",
      "2   1   0   0   0  unknown  -1  0.1  \n",
      "3   0   0   0   0  unknown  -1  0.1  \n",
      "4   1   1   0   0  unknown   1  0.1  \n",
      "5   0   1   0   0  unknown  -1  0.1  \n",
      "6   0   0   0   0  unknown  -1  0.1  \n",
      "7   1   0   0   0  unknown   1  0.1  \n",
      "8   0   0   1   1  success   1  0.1  \n",
      "9   1   0   0   0  unknown  -1  0.1  \n"
     ]
    }
   ],
   "source": [
    "attrib_name = {0:\"age\", 1:\"job\",2:\"marital\",3:\"education\",4:\"default\",5:\"balance\", 6:\"housing\",7:\"loan\",8:\"contact\",9:\"day\",10:\"month\",11:\"duration\",12:\"campaign\",13:\"pdays\",14:\"previous\",15:\"poutcome\"}\n",
    "label_values = [1, -1]\n",
    "\n",
    "categorical_attrib_values = { \"job\":     [\"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\", \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\"],\\\n",
    "                 \"marital\":  [\"married\",\"divorced\",\"single\"],\\\n",
    "                 \"education\":[\"unknown\",\"secondary\",\"primary\",\"tertiary\"],\\\n",
    "                 \"default\":  [\"yes\",\"no\"],\\\n",
    "                 \"housing\":  [\"yes\",\"no\"],\\\n",
    "                 \"loan\":     [\"yes\",\"no\"],\\\n",
    "                 \"contact\":  [\"unknown\",\"telephone\",\"cellular\"],\\\n",
    "                 \"month\":    [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"],\\\n",
    "                 \"poutcome\": [\"unknown\",\"other\",\"failure\",\"success\"]\n",
    "                }\n",
    "def convert_numerical_to_binary(df, Label_col_index):\n",
    "    for col_idx in range(Label_col_index):\n",
    "        if attrib_name[col_idx] not in categorical_attrib_values:\n",
    "            df[col_idx] = pd.to_numeric(df[col_idx], errors='coerce')\n",
    "            threashold = df[col_idx].median()\n",
    "            print(\"preprocessing numerical attribute:\", attrib_name[col_idx], \"threashold:\", threashold)\n",
    "            df[col_idx] = df[col_idx].apply(lambda x: 0 if int(x) <= threashold else 1)\n",
    "\n",
    "######## convert the numerical to binary\n",
    "train_df_processed = train_df\n",
    "test_df_processed = test_df\n",
    "convert_numerical_to_binary(train_df_processed, 16)\n",
    "convert_numerical_to_binary(test_df_processed, 16)\n",
    "\n",
    "######## convert label: yes->+1 no-> -1\n",
    "train_df_processed[16] = train_df_processed[16].apply(lambda x: -1 if x=='no' else 1)\n",
    "test_df_processed[16] = test_df_processed[16].apply(lambda x: -1 if x=='no' else 1)\n",
    "\n",
    "######## the the initial weights as a column to the dataframe\n",
    "Dtrain = [1/m_train] * m_train\n",
    "train_df_processed[17] = Dtrain\n",
    "print(train_df_processed)\n",
    "Dtest  = [1/m_test]  * m_test\n",
    "test_df_processed[17] = Dtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gain functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the information gain\n",
    "def entropy_gain(S,Label_col_index, attrib_idx):\n",
    "    H_S = S.groupby(Label_col_index)[Label_col_index + 1]\\\n",
    "    .apply(lambda x: (x.sum())*np.log2(x.sum()))\\\n",
    "    .sum()*-1\n",
    "    grpSizeRatio = S.groupby(attrib_idx,as_index=False)[attrib_idx].apply(lambda x: x.count()/S.shape[0])\n",
    "    print(grpSizeRatio)\n",
    "    print(\"====\")\n",
    "    \n",
    "    temp1 = S.groupby([attrib_idx,Label_col_index],as_index=False)[Label_col_index+1].sum()\n",
    "    print(temp1)\n",
    "    print(\"====\")\n",
    "    \n",
    "    temp2 = temp1.groupby(attrib_idx).apply(lambda x:((x[Label_col_index+1]/x[Label_col_index+1].sum())*np.log2(x[Label_col_index+1]/x[Label_col_index+1].sum())))\n",
    "    print(temp2)\n",
    "    print(\"====\")\n",
    "    return H_S - Expected_H_Sv\n",
    "\n",
    "# calculates the information gain\n",
    "# def entropy_gain(S,Label_col_index, attrib_idx):\n",
    "#     H_S = S.groupby(Label_col_index)[Label_col_index + 1]\\\n",
    "#     .apply(lambda x: (x.sum()/S.shape[0])*np.log2(x.sum()/S.shape[0]))\\\n",
    "#     .sum()*-1\n",
    "    \n",
    "#     Expected_H_Sv = S.groupby([attrib_idx,Label_col_index],as_index=False)[Label_col_index+1].sum()\\\n",
    "#     .groupby(attrib_idx)[Label_col_index+1].apply(lambda x:(x.sum()/S.shape[0])*((x/x.sum())*np.log2(x/x.sum()))).sum()*-1\n",
    "        \n",
    "#     return H_S - Expected_H_Sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# id3 and prediction fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# returns the column index of the best splitter attribute\n",
    "# S: set of examples\n",
    "# Attributes: list of attributes to be evaluated\n",
    "# splitter_algorithm: the splitter algorithm, can be one of the 3 values (\"ME\":Majority Error, \"GI\":Gini Index, \"EN\":Entropy)\n",
    "def Best_spliter_attribute(S, Attributes, Label_col_index, splitter_algorithm):\n",
    "    if len(Attributes) < 2:\n",
    "        return Attributes[0]\n",
    "    best_gain = 0\n",
    "    best_attribute = Attributes[0] #\n",
    "    for v in Attributes:\n",
    "        if v != Label_col_index:\n",
    "            gain_v = 0\n",
    "            if splitter_algorithm == \"EN\":\n",
    "                gain_v = entropy_gain(S,Label_col_index, v)\n",
    "                print(\"attrib:\",attrib_name[v], \"gain:\",gain_v)\n",
    "            else:\n",
    "                assert False, \"Unknown splitter_algorithm:\" + splitter_algorithm + \"!!!\"\n",
    "            if gain_v > best_gain:\n",
    "                best_gain = gain_v\n",
    "                best_attribute = v\n",
    "    return best_attribute\n",
    "\n",
    "def numeric_attrib_value(S, attrib_col_idx, numeric_value):\n",
    "    threashold = S[attrib_col_idx].median()\n",
    "    return numeric_value >= threashold   \n",
    "\n",
    "def predict(root, entry, Label_col_index):\n",
    "    example = {} \n",
    "    for i in range(Label_col_index):\n",
    "        example[attrib_name[i]] = entry[i]\n",
    "    return predict_helper(root, example)\n",
    "\n",
    "def predict_helper(root, example):\n",
    "    if isinstance(root, list): # if attrib-node\n",
    "        root_attrib_name = root[0]\n",
    "    else:\n",
    "        return root\n",
    "    example_attrib_val = example[root_attrib_name]\n",
    "    if isinstance(root[1][example_attrib_val], list): # if attrib-node\n",
    "        return predict_helper(root[1][example_attrib_val], example)\n",
    "    else: # if leaf node\n",
    "        return root[1][example_attrib_val]\n",
    "    \n",
    "def predict_dataset(S, root, Label_col_index):\n",
    "    all = 0\n",
    "    correct = 0\n",
    "    for idx, row in S.iterrows():\n",
    "        all += 1\n",
    "        gold_label = row[Label_col_index]\n",
    "        predicted_label = predict(root, row, Label_col_index)\n",
    "        if predicted_label == gold_label:\n",
    "            correct +=1\n",
    "    return correct / all # accuracy \n",
    "        \n",
    "# ##############              ID3 implementation:\n",
    "# Input:\n",
    "# S: the set of Examples\n",
    "# Attributes: the set of measured attributes\n",
    "# Label_col_index: column index of the target attribute (the prediction)\n",
    "# max_tree_level: bounds the height of the tree\n",
    "# splitter_algorithm: can be one of the 3 values (\"ME\":Majority Error, \"GI\":Gini Index, \"EN\":Entropy)\n",
    "def ID3(S, Attributes, Label_col_index, max_tree_level, splitter_algorithm):\n",
    "    if(max_tree_level == 0):                                                            # if at max level\n",
    "        return S[Label_col_index].mode()[0]   \n",
    "    elif S[Label_col_index].nunique() == 1:                                             # if all examples have same label:   \n",
    "        return S[Label_col_index].mode()[0]\n",
    "    elif len(Attributes) == 0:                                                          # if Attributes empty\n",
    "        return S[Label_col_index].mode()[0]\n",
    "    else:\n",
    "        # 1. Create a Root node for tree\n",
    "        Root = [] # each \"attribute node\" is a list s.t. \n",
    "                                                    # 1st element = string attribute name\n",
    "                                                    # 2nd element = dictionary children;\n",
    "                                                            # key = each possible attribute value v\n",
    "                                                            # value = an \"attribute node\" list;  or a string label for leaf nodes\n",
    "        # 2. A = attribute in Attributes that best splits S\n",
    "        A = Best_spliter_attribute(S, Attributes, Label_col_index, splitter_algorithm)\n",
    "#         print(\"best is:\",attrib_name[A])\n",
    "        Root.append(attrib_name[A]) # 1st element = string attribute name\n",
    "        Root.append({})             # 2nd element = dictionary children;\n",
    "        # 3. for each possible value v of that A can take:\n",
    "        attribute_values=[]\n",
    "        if(attrib_name[A] in categorical_attrib_values):\n",
    "            attribute_values = categorical_attrib_values[attrib_name[A]]\n",
    "        else: # o.w. it is numerical \n",
    "            attribute_values = [0,1]\n",
    "        for v in attribute_values:\n",
    "            # 1. Add a new tree branch corresponding to A=v\n",
    "            # 2. Let Sv be the subset of examples in S with A=v\n",
    "            Sv = S.loc[S[A] == v]\n",
    "            if len(Sv) == 0: # if Sv is empty\n",
    "                Root[1][v] = S[Label_col_index].mode()[0] # string label\n",
    "            else:\n",
    "                Attrib_minus_A = Attributes\n",
    "                if len(Attrib_minus_A) > 0 and A in Attrib_minus_A:\n",
    "                    Attrib_minus_A.remove(A)\n",
    "                Root[1][v] = ID3(Sv, Attrib_minus_A,Label_col_index, max_tree_level-1,splitter_algorithm) # an \"attribute node\" list;\n",
    "        return Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some  Training examples ...\n",
      "     0\n",
      "0  0.5\n",
      "1  0.5\n",
      "====\n",
      "   0   16   17\n",
      "0   0  -1  0.2\n",
      "1   0   1  0.3\n",
      "2   1  -1  0.5\n",
      "====\n",
      "0  0   -0.528771\n",
      "   1   -0.442179\n",
      "1  2    0.000000\n",
      "Name: 17, dtype: float64\n",
      "====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Expected_H_Sv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7ea9c8dbc63d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Some  Training examples ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mAttributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# initially put all attributes except the label in Attributes set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtree_infoGain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"EN\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# note the max_height is set to 2 to construct decision stumps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_infoGain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c03f7cd267b8>\u001b[0m in \u001b[0;36mID3\u001b[0;34m(S, Attributes, Label_col_index, max_tree_level, splitter_algorithm)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                                             \u001b[0;31m# value = an \"attribute node\" list;  or a string label for leaf nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# 2. A = attribute in Attributes that best splits S\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBest_spliter_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabel_col_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitter_algorithm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;31m#         print(\"best is:\",attrib_name[A])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mRoot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrib_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1st element = string attribute name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c03f7cd267b8>\u001b[0m in \u001b[0;36mBest_spliter_attribute\u001b[0;34m(S, Attributes, Label_col_index, splitter_algorithm)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mgain_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msplitter_algorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"EN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mgain_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropy_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLabel_col_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"attrib:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattrib_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gain:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgain_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ac7f47c9d814>\u001b[0m in \u001b[0;36mentropy_gain\u001b[0;34m(S, Label_col_index, attrib_idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mH_S\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mExpected_H_Sv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# calculates the information gain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Expected_H_Sv' is not defined"
     ]
    }
   ],
   "source": [
    "# ##############              test the decision stump\n",
    "print(\"Some  Training examples ...\")\n",
    "Attributes = [0,1,2,3,4,5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] # initially put all attributes except the label in Attributes set\n",
    "tree_infoGain = ID3(train_df_processed, Attributes,16,1, \"EN\")  # note the max_height is set to 2 to construct decision stumps\n",
    "print(tree_infoGain)\n",
    "\n",
    "print(\"#######\")\n",
    "print(\"train accuracy:\",predict_dataset(train_df_processed, tree_infoGain,16))\n",
    "print(\"test accuracy:\",predict_dataset(test_df_processed, tree_infoGain,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Et(S, root, Label_col_index):\n",
    "    Et = 0\n",
    "    ht_x = []\n",
    "    for idx, row in S.iterrows():\n",
    "        gold_label = row[Label_col_index]\n",
    "        predicted_label = predict(root, row, Label_col_index)\n",
    "        ht_x.append(predicted_label)\n",
    "        if predicted_label != gold_label:\n",
    "            Et += row[Label_col_index + 1]\n",
    "    return Et, ht_x\n",
    "\n",
    "# ##############              AdaBoost_train implementation:\n",
    "# Input:\n",
    "# S: the set of Examples\n",
    "# Attributes: the set of measured attributes\n",
    "# Label_col_index: column index of the target attribute (the prediction)\n",
    "# T: number of iterations\n",
    "def AdaBoost_train(S, Label_col_index, T):\n",
    "    print(\"AdaBoost Training...\")\n",
    "    print(\"Total iterations:\",T)\n",
    "    \n",
    "    # 1. Initialize D1(i) = 1/m for all i = 1, 2, ..., m\n",
    "    h=[]\n",
    "    alpha=[]\n",
    "    # 2. For t = 1, 2, ..., T:\n",
    "    for t in range(T):\n",
    "        print(\"iteration:\",t)\n",
    "        Attributes = [0,1,2,3,4,5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "        # 1. Find a classifier ht whose weighted classification error is better than chance\n",
    "#         print(Attributes)\n",
    "        Hyp = ID3(S, Attributes, Label_col_index, 1, \"EN\")\n",
    "        print(Hyp)\n",
    "#         print(\"stump_\",t ,\" test accuracy:\",predict_dataset(test_df_processed, Hyp,16))\n",
    "        h.append(Hyp)\n",
    "        # compute the Et\n",
    "        Et = 0\n",
    "        ht_x = []\n",
    "        Et, ht_x = get_Et(S,Hyp, Label_col_index)\n",
    "        # compute Zt        \n",
    "        Zt = 2*math.sqrt(Et * (1 - Et))\n",
    "        # 2. Compute its vote\n",
    "        Alp = 0.5 * math.log((1-Et)/Et)\n",
    "        alpha.append(Alp)\n",
    "        # 3. Update the  values of the weights for the training examples\n",
    "        temp = S[Label_col_index+1].mul(pd.Series(ht_x))\n",
    "        temp = temp.apply(lambda x: math.exp(-1*Alp*x))\n",
    "        S[Label_col_index+1] = (S[Label_col_index+1]/Zt).mul(temp)\n",
    "        print(S[Label_col_index+1])\n",
    "        print(Et,Alp)\n",
    "    # 3. Return the final hypothesis\n",
    "    return h, alpha\n",
    "\n",
    "# ##############              AdaBoost_predict implementation:\n",
    "# Input: \n",
    "# h[1:T]: list of decision stumps\n",
    "# alpha[1:T]: list of votes\n",
    "# x: example to be predicted\n",
    "def AdaBoost_predict(h, alpha, x, Label_col_index):\n",
    "    ht_x =[]\n",
    "    for t in range(len(h)):\n",
    "        ht_x.append(predict(h[t],x,Label_col_index))\n",
    "    return np.sign(np.dot(ht_x, alpha))\n",
    "\n",
    "def AdaBoost_predict_dataset(S, h,alpha, Label_col_index):\n",
    "    all = 0\n",
    "    correct = 0\n",
    "    for idx, row in S.iterrows():\n",
    "        all += 1\n",
    "        gold_label = row[Label_col_index]\n",
    "        predicted_label = AdaBoost_predict(h,alpha, row, Label_col_index)\n",
    "        if predicted_label == gold_label:\n",
    "            correct +=1\n",
    "    return correct / all # accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## the the initial weights as a column to the dataframe\n",
    "Dtrain = [1/m_train] * m_train\n",
    "train_df_processed[17] = Dtrain\n",
    "\n",
    "Dtest  = [1/m_test]  * m_test\n",
    "test_df_processed[17] = Dtest\n",
    "# ##############              test the AdaBoost\n",
    "h, alpha = AdaBoost_train(train_df_processed, 16, 50)\n",
    "print(h)\n",
    "print(alpha)\n",
    "print(\"#######\")\n",
    "print(\"train accuracy:\",AdaBoost_predict_dataset(train_df_processed,h,alpha,16))\n",
    "print(\"test accuracy:\",AdaBoost_predict_dataset(test_df_processed,h,alpha,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

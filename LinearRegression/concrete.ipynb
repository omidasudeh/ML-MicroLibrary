{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fixed-luxury",
   "metadata": {},
   "source": [
    "# Read the input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sapphire-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import copy as cp\n",
    "import sys\n",
    "import pickle\n",
    "train_raw = pd.read_csv(\"./concrete/train.csv\", header=None).values\n",
    "cols = train_raw.shape[1]\n",
    "rows = train_raw.shape[0]\n",
    "train_x = np.copy(train_raw)\n",
    "train_x[:,cols - 1] = 1\n",
    "train_y = train_raw[:, cols - 1]\n",
    "\n",
    "test_raw = pd.read_csv(\"./concrete/test.csv\", header=None).values\n",
    "cols = test_raw.shape[1]\n",
    "rows = test_raw.shape[0]\n",
    "test_x = np.copy(test_raw)\n",
    "test_x[:,cols - 1] = 1\n",
    "test_y = test_raw[:, cols - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "applicable-december",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.reshape(train_y, (-1,1)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-wrapping",
   "metadata": {},
   "source": [
    "# Batched LMS Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "little-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradien_Decent(x,y):\n",
    "    m = x.shape[0]\n",
    "    n = x.shape[1]\n",
    "    Error = 1\n",
    "    threshold = 10e-6\n",
    "    Max_iter = 10000\n",
    "    LearningRate = 0.01\n",
    "    w = np.zeros([n,1])\n",
    "    Costs = []\n",
    "    iter = 0\n",
    "    while Error > threshold and iter < Max_iter:\n",
    "        iter = iter + 1\n",
    "        diff = np.matmul(x, w) - np.reshape(y, (-1,1))      \n",
    "        gradient = np.sum(x * (diff), axis = 0)\n",
    "        w1 = w - LearningRate*np.reshape(gradient,(-1,1))\n",
    "        Error = np.sum(np.abs(w - w1))\n",
    "        w = w1\n",
    "        cost = 0.5 * np.sum(np.square(diff))\n",
    "        Costs.append([iter, cost])\n",
    "    print(\"converged after \", iter, \"iterations.\")\n",
    "    return w, Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "golden-loading",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged after  5859 iterations.\n",
      "Batched Gradien_Decent W vector:\n",
      "[[ 0.89919933]\n",
      " [ 0.78488638]\n",
      " [ 0.84952298]\n",
      " [ 1.29780387]\n",
      " [ 0.12966251]\n",
      " [ 1.57041505]\n",
      " [ 0.99730037]\n",
      " [-0.01522461]]\n"
     ]
    }
   ],
   "source": [
    "w, Costs = Gradien_Decent(train_x, train_y)\n",
    "print(\"Batched Gradien_Decent W vector:\")\n",
    "print(w)\n",
    "from numpy import savetxt\n",
    "savetxt('Costs.csv', Costs, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "satellite-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched Test_Cost: 23.359919165485493\n"
     ]
    }
   ],
   "source": [
    "Test_Cost = 0.5 * np.sum(np.square(np.reshape(np.squeeze(np.matmul(test_x,w)) - test_y, (-1,1))))\n",
    "print('Batched Test_Cost:', Test_Cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-nation",
   "metadata": {},
   "source": [
    "# Stocastic LMS Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quality-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stoc_Gradien_Decent(x,y):\n",
    "    m = x.shape[0]\n",
    "    n = x.shape[1]\n",
    "    Error = 1\n",
    "    threshold = 10e-6\n",
    "    Max_iter = 100000\n",
    "    LearningRate = 0.01\n",
    "    w = np.zeros([n,1])\n",
    "    Costs = []\n",
    "    iter = 0\n",
    "    while Error > threshold and iter < Max_iter:\n",
    "        iter = iter + 1\n",
    "        idx = np.random.randint(m,size=1)\n",
    "        x1 = x[idx]\n",
    "        y1 = y[idx]\n",
    "        SG = (y1 - np.dot(x1, w))*x1 \n",
    "        w1 = w + LearningRate* np.reshape(SG, (-1,1))\n",
    "        Error = np.sum(np.abs(w - w1))\n",
    "        w = w1\n",
    "        cost = 0.5 * np.sum(np.square(np.matmul(x, w) - np.reshape(y, (-1,1))))\n",
    "        Costs.append([iter, cost])\n",
    "    print(\"converged after \", iter, \"iterations.\")\n",
    "    return w, Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informal-filing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged after  31982 iterations.\n",
      "Stocastic Gradien_Decent W vector:\n",
      "[[ 0.40661914]\n",
      " [ 0.28404155]\n",
      " [ 0.27415111]\n",
      " [ 0.86267859]\n",
      " [-0.02599699]\n",
      " [ 0.85171128]\n",
      " [ 0.4460168 ]\n",
      " [ 0.14977482]]\n"
     ]
    }
   ],
   "source": [
    "w, Costs = Stoc_Gradien_Decent(train_x, train_y)\n",
    "print(\"Stocastic Gradien_Decent W vector:\")\n",
    "print(w)\n",
    "from numpy import savetxt\n",
    "savetxt('Stoc_Costs.csv', Costs, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continuing-defensive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stocastic Test_Cost: 23.180313947184068\n"
     ]
    }
   ],
   "source": [
    "Test_Cost = 0.5 * np.sum(np.square(np.reshape(np.squeeze(np.matmul(test_x,w)) - test_y, (-1,1))))\n",
    "print('Stocastic Test_Cost:', Test_Cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-philippines",
   "metadata": {},
   "source": [
    "# Analytical LMS Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expired-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analytical_Gradien_Decent(x, y):\n",
    "    x_t = np.transpose(x)\n",
    "    return np.matmul(np.linalg.inv(np.matmul(x_t, x)),np.matmul(x_t, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "editorial-roller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical Gradien_Decent W vector:\n",
      "[ 0.90056451  0.78629331  0.85104314  1.29889413  0.12989067  1.57224887\n",
      "  0.99869359 -0.01519667]\n",
      "Analytical Test_Cost: 23.36176447993874\n"
     ]
    }
   ],
   "source": [
    "w = Analytical_Gradien_Decent(train_x, train_y)\n",
    "Test_Cost = 0.5 * np.sum(np.square(np.reshape(np.squeeze(np.matmul(test_x,w)) - test_y, (-1,1))))\n",
    "print(\"Analytical Gradien_Decent W vector:\")\n",
    "print(w)\n",
    "print('Analytical Test_Cost:', Test_Cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the input traning and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./car/test.csv\", header=None)\n",
    "train_df = pd.read_csv(\"./car/train.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train summary:\n",
      "            0     1     2     3     4     5      6\n",
      "count    1000  1000  1000  1000  1000  1000   1000\n",
      "unique      4     4     4     3     3     3      4\n",
      "top     vhigh  high     3     4   big   med  unacc\n",
      "freq      259   255   253   337   341   344    698\n",
      "===============\n",
      "test summary:\n",
      "          0      1      2     3    4     5      6\n",
      "count   728    728    728   728  728   728    728\n",
      "unique    4      4      4     3    3     3      4\n",
      "top     low  vhigh  5more  more  med  high  unacc\n",
      "freq    190    188    190   248  247   249    512\n"
     ]
    }
   ],
   "source": [
    "print(\"train summary:\")\n",
    "print(train_df.describe())\n",
    "print(\"===============\")\n",
    "print(\"test summary:\")\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0      1      2     3      4     5      6\n",
      "705  vhigh  vhigh      3     2    med   med  unacc\n",
      "166    med  vhigh  5more     4  small   med  unacc\n",
      "265   high    med      4     2  small   low  unacc\n",
      "391    med   high      3     2    big   low  unacc\n",
      "160    low    low      4  more  small  high   good\n",
      "625   high   high      4  more  small   med  unacc\n",
      "499   high   high  5more  more    big   low  unacc\n",
      "225    med    med      4     2  small  high  unacc\n",
      "311    med  vhigh      3     2    med   med  unacc\n",
      "299  vhigh    med  5more  more  small   med  unacc\n",
      "634  vhigh  vhigh      2     2    med   med  unacc\n",
      "147    med  vhigh      2     4    big   low  unacc\n",
      "251  vhigh    med  5more     2    big   med  unacc\n",
      "146    low   high      2  more    med   med    acc\n",
      "668   high    low  5more     4  small  high    acc\n",
      "467  vhigh   high      4  more  small   low  unacc\n",
      "206    low   high  5more     4    big   med    acc\n",
      "439   high    low      4     4  small   med  unacc\n",
      "257    low    low      2     2    med  high  unacc\n",
      "593    med    low      2  more    med   low  unacc\n"
     ]
    }
   ],
   "source": [
    "sample = test_df.sample(20)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the information gain\n",
    "def entropy(S, Attribute_col_index, Label_col_index):\n",
    "    print(\"entropy\")\n",
    "\n",
    "# calculates the gini index\n",
    "def gini():\n",
    "    print(\"gini\")\n",
    "    \n",
    "# calculates the majority error\n",
    "def majority_error(S,Label_col_index, attrib_idx):\n",
    "#     print(\"Calculating Majority Error ...\")\n",
    "    freq = S.groupby(Label_col_index)[Label_col_index].count()\n",
    "#     print(freq)\n",
    "    ME_S = (freq.sum()- freq.max())/ freq.sum()\n",
    "#     print(\"ME(S)=\" + str(ME_S))\n",
    "#     test = S.groupby([attrib_idx,Label_col_index])[Label_col_index].count()\n",
    "#     print(test)\n",
    "    attrib_label_grouped = S.groupby([attrib_idx,Label_col_index],as_index=False)[Label_col_index].count()\n",
    "#     print(attrib_label_grouped)\n",
    "#     print(attrib_label_grouped.groupby(attrib_idx).apply(lambda grp: (grp.sum()-grp.max())))\n",
    "#     print(attrib_label_grouped.groupby(attrib_idx).apply(lambda grp: (grp.sum()-grp.max())/grp.sum()))\n",
    "#     print(attrib_label_grouped.groupby(attrib_idx).apply(lambda grp: (grp.sum()/freq.sum())))\n",
    "#     print(attrib_label_grouped.groupby(attrib_idx).apply(lambda grp: (grp.sum()/freq.sum())*(grp.sum()-grp.max())/grp.sum()))\n",
    "    Expected_ME_of_attrib_values = attrib_label_grouped.groupby(attrib_idx).apply(lambda grp: (grp.sum()/freq.sum())*(grp.sum()-grp.max())/grp.sum()).sum()\n",
    "#     print(\"Expected_ME_of_attrib_values=\",Expected_ME_of_attrib_values)\n",
    "    gain = ME_S - Expected_ME_of_attrib_values\n",
    "    print(\"gain of attrib index \", attrib_idx, \"=\", gain[Label_col_index])\n",
    "    print(\"-------\")\n",
    "    return gain[Label_col_index]\n",
    "\n",
    "# returns the column index of the best splitter attribute\n",
    "# S: set of examples\n",
    "# Attributes: list of attributes to be evaluated\n",
    "# splitter_algorithm: the splitter algorithm, can be one of the 3 values (\"ME\":Majority Error, \"GI\":Gini Index, \"EN\":Entropy)\n",
    "def Best_spliter_attribute(S, Attributes, Label_col_index, splitter_algorithm):\n",
    "    print(\"splitter algorithm:\"  + splitter_algorithm)\n",
    "    if len(Attributes) < 2:\n",
    "        return Attributes[0]\n",
    "    best_gain = 0\n",
    "    best_attribute = Attributes[0]\n",
    "    for v in Attributes:\n",
    "        if v != Label_col_index:\n",
    "            print(\"finding gain for attribute with col-idx=\",str(v))\n",
    "            gain_v = 0\n",
    "            if splitter_algorithm == \"EN\":\n",
    "                gain_v = entropy(S,Label_col_index, v)\n",
    "            elif splitter_algorithm == \"ME\":\n",
    "                print(\"using ME algorithm\")\n",
    "                gain_v = majority_error(S,Label_col_index,v)\n",
    "            elif splitter_algorithm == \"GI\":\n",
    "                gain_v = gini(S,Label_col_index,v)\n",
    "            else:\n",
    "                assert False, \"Unknown splitter_algorithm:\" + splitter_algorithm + \"!!!\"\n",
    "            if gain_v > best_gain:\n",
    "                best_gain = gain_v\n",
    "                best_attribute = v\n",
    "    print(\"best attrib is:\",best_attribute)\n",
    "    return best_attribute\n",
    "\n",
    "atrib_name = {0:\"buying\", 1:\"maint\",2:\"doors\",3:\"persons\",4:\"lug_boot\",5:\"safety\"}\n",
    "\n",
    "def predict(root, entry):\n",
    "    example = {} \n",
    "    for i in range(6):\n",
    "        example[atrib_name[i]] = entry[i]\n",
    "    print(example)\n",
    "    #{'buying': 'low', 'maint': 'high', 'doors': '2', 'persons': 'more', 'lug_boot': 'small', 'safety': 'low'}\n",
    "    return predic_helper(root, example)\n",
    "\n",
    "def predic_helper(root, example):\n",
    "    root_attrib_name = root[0]\n",
    "    example_attrib_val = example[root_attrib_name]\n",
    "    if isinstance(root[1][example_attrib_val], list): # if attrib-node\n",
    "        return predic_helper(root[1][example_attrib_val], example)\n",
    "    else: # if leaf node\n",
    "        return root[1][example_attrib_val]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitter algorithm:ME\n",
      "finding gain for attribute with col-idx= 0\n",
      "using ME algorithm\n",
      "gain of attrib index  0 = 0.0\n",
      "-------\n",
      "finding gain for attribute with col-idx= 1\n",
      "using ME algorithm\n",
      "gain of attrib index  1 = 0.0\n",
      "-------\n",
      "finding gain for attribute with col-idx= 2\n",
      "using ME algorithm\n",
      "gain of attrib index  2 = 0.0\n",
      "-------\n",
      "finding gain for attribute with col-idx= 3\n",
      "using ME algorithm\n",
      "gain of attrib index  3 = -5.551115123125783e-17\n",
      "-------\n",
      "finding gain for attribute with col-idx= 4\n",
      "using ME algorithm\n",
      "gain of attrib index  4 = -5.551115123125783e-17\n",
      "-------\n",
      "finding gain for attribute with col-idx= 5\n",
      "using ME algorithm\n",
      "gain of attrib index  5 = 0.0\n",
      "-------\n",
      "best attrib is: 0\n",
      "splitter algorithm:ME\n",
      "finding gain for attribute with col-idx= 1\n",
      "using ME algorithm\n",
      "gain of attrib index  1 = 0.0\n",
      "-------\n",
      "finding gain for attribute with col-idx= 2\n",
      "using ME algorithm\n",
      "gain of attrib index  2 = 0.0\n",
      "-------\n",
      "finding gain for attribute with col-idx= 3\n",
      "using ME algorithm\n",
      "gain of attrib index  3 = 0.0\n",
      "-------\n",
      "finding gain for attribute with col-idx= 4\n",
      "using ME algorithm\n",
      "gain of attrib index  4 = 0.0\n",
      "-------\n",
      "finding gain for attribute with col-idx= 5\n",
      "using ME algorithm\n",
      "gain of attrib index  5 = 2.7755575615628914e-17\n",
      "-------\n",
      "best attrib is: 5\n",
      "splitter algorithm:ME\n",
      "finding gain for attribute with col-idx= 1\n",
      "using ME algorithm\n",
      "gain of attrib index  1 = 0.0\n",
      "-------\n",
      "finding gain for attribute with col-idx= 2\n",
      "using ME algorithm\n",
      "gain of attrib index  2 = 0.0\n",
      "-------\n",
      "finding gain for attribute with col-idx= 3\n",
      "using ME algorithm\n",
      "gain of attrib index  3 = 0.0\n",
      "-------\n",
      "finding gain for attribute with col-idx= 4\n",
      "using ME algorithm\n",
      "gain of attrib index  4 = 0.017543859649122806\n",
      "-------\n",
      "best attrib is: 4\n",
      "splitter algorithm:ME\n",
      "finding gain for attribute with col-idx= 1\n",
      "using ME algorithm\n",
      "gain of attrib index  1 = 0.047619047619047616\n",
      "-------\n",
      "finding gain for attribute with col-idx= 2\n",
      "using ME algorithm\n",
      "gain of attrib index  2 = 0.0\n",
      "-------\n",
      "finding gain for attribute with col-idx= 3\n",
      "using ME algorithm\n",
      "gain of attrib index  3 = 0.0\n",
      "-------\n",
      "best attrib is: 1\n",
      "splitter algorithm:ME\n",
      "finding gain for attribute with col-idx= 2\n",
      "using ME algorithm\n",
      "gain of attrib index  2 = 0.16666666666666669\n",
      "-------\n",
      "finding gain for attribute with col-idx= 3\n",
      "using ME algorithm\n",
      "gain of attrib index  3 = 0.33333333333333337\n",
      "-------\n",
      "best attrib is: 3\n",
      "splitter algorithm:ME\n",
      "['buying', {'vhigh': ['safety', {'low': 'unacc', 'med': ['lug_boot', {'med': ['maint', {'med': ['persons', {'2': 'unacc', 'more': 'acc', '4': ['doors', {'4': 'acc', '2': 'unacc'}]}], 'low': 'acc', 'vhigh': 'unacc', 'high': 'unacc'}], 'small': 'unacc', 'big': 'acc'}], 'high': 'unacc'}], 'low': 'unacc', 'high': 'unacc', 'med': 'unacc'}]\n",
      "#######\n",
      "{'buying': 'low', 'maint': 'high', 'doors': '2', 'persons': 'more', 'lug_boot': 'med', 'safety': 'med'}\n",
      "['low', 'high', '2', 'more', 'med', 'med', 'acc'] label is unacc\n"
     ]
    }
   ],
   "source": [
    "# ##############              ID3 implementation:\n",
    "# Input:\n",
    "# S: the set of Examples\n",
    "# Attributes: the set of measured attributes\n",
    "# Label_col_index: column index of the target attribute (the prediction)\n",
    "# max_tree_level: bounds the height of the tree\n",
    "# splitter_algorithm: can be one of the 3 values (\"ME\":Majority Error, \"GI\":Gini Index, \"EN\":Entropy)\n",
    "def ID3(S, Attributes, Label_col_index, max_tree_level, splitter_algorithm):\n",
    "    if S[Label_col_index].nunique() == 1:                                               # if all examples have same label:   \n",
    "        return S[Label_col_index].mode()[0]\n",
    "    elif len(Attributes) == 0:                                                          # if Attributes empty\n",
    "        return S[Label_col_index].mode()[0]\n",
    "    else:\n",
    "        # 1. Create a Root node for tree\n",
    "        Root = [] # each \"attribute node\" is a list s.t. \n",
    "                                                    # 1st element = string attribute name\n",
    "                                                    # 2nd element = dictionary children;\n",
    "                                                            # key = each possible attribute value v\n",
    "                                                            # value = an \"attribute node\" list;  or a string label for leaf nodes\n",
    "        # 2. A = attribute in Attributes that best splits S\n",
    "        A = Best_spliter_attribute(S, Attributes, Label_col_index, splitter_algorithm)\n",
    "        Root.append(atrib_name[A]) # 1st element = string attribute name\n",
    "        Root.append({})            # 2nd element = dictionary children;\n",
    "        # 3. for each possible value v of that A can take:\n",
    "        for v in S[A].unique(): # TODO: S[A].unique() might not include all possible value \n",
    "            # 1. Add a new tree branch corresponding to A=v\n",
    "            # 2. Let Sv be the subset of examples in S with A=v\n",
    "            Sv = S.loc[S[A] == v]\n",
    "            if len(Sv) == 0:\n",
    "                Root[1][v] = S[Label_col_index].mode()[0] # string label\n",
    "            else:\n",
    "                Attrib_minus_A = Attributes\n",
    "                if len(Attrib_minus_A) > 0 and A in Attrib_minus_A:\n",
    "                    Attrib_minus_A.remove(A)\n",
    "                Root[1][v] = ID3(Sv, Attrib_minus_A,Label_col_index, max_tree_level,splitter_algorithm) # an \"attribute node\" list;\n",
    "        return Root\n",
    "        \n",
    "######            main\n",
    "Attributes = [0,1,2,3,4,5] # initially put all attributes except the label in Attributes set\n",
    "tree = ID3(test_df, Attributes,6, 10, \"ME\")\n",
    "print(tree)\n",
    "print(\"#######\")\n",
    "entry = [\"low\",\"high\" ,     \"2\",  \"more\"  ,  \"med\"  , \"med\" ,   \"acc\"]\n",
    "print(entry, \"label is\", predict(tree, entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

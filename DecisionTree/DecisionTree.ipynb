{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the input traning and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./car/test.csv\", header=None)\n",
    "train_df = pd.read_csv(\"./car/train.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train summary:\n",
      "            0     1     2     3     4     5      6\n",
      "count    1000  1000  1000  1000  1000  1000   1000\n",
      "unique      4     4     4     3     3     3      4\n",
      "top     vhigh  high     4     4   big   med  unacc\n",
      "freq      259   255   253   337   341   344    698\n",
      "===============\n",
      "test summary:\n",
      "          0      1      2     3    4     5      6\n",
      "count   728    728    728   728  728   728    728\n",
      "unique    4      4      4     3    3     3      4\n",
      "top     low  vhigh  5more  more  med  high  unacc\n",
      "freq    190    188    190   248  247   249    512\n"
     ]
    }
   ],
   "source": [
    "print(\"train summary:\")\n",
    "print(train_df.describe())\n",
    "print(\"===============\")\n",
    "print(\"test summary:\")\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0      1      2     3      4     5      6\n",
      "688    med    low      4  more    big  high  vgood\n",
      "434    low    low      4     4    big   med   good\n",
      "258    low  vhigh      3     2    big  high  unacc\n",
      "502    low    low      3     4  small   low  unacc\n",
      "355    low    low      2     2    med   low  unacc\n",
      "438  vhigh  vhigh      2  more    med   low  unacc\n",
      "335   high    low      3     2    big  high  unacc\n",
      "592    med    med      2     4  small   low  unacc\n",
      "92     med  vhigh      3     4    big   low  unacc\n",
      "514   high   high  5more  more    med   med    acc\n",
      "131    med    med      3     2  small   med  unacc\n",
      "519    low   high      3  more    med  high  vgood\n",
      "110  vhigh  vhigh      3     4    big   med  unacc\n",
      "38    high   high      2  more    med   med  unacc\n",
      "346    low   high  5more  more    med  high  vgood\n",
      "77     med    low      4  more  small   med    acc\n",
      "545    med    low      3     2    big   low  unacc\n",
      "712    low    med      3     2    big  high  unacc\n",
      "542  vhigh   high  5more     4    med   low  unacc\n",
      "56     low    low      4  more    big  high  vgood\n"
     ]
    }
   ],
   "source": [
    "sample = test_df.sample(20)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini-tree\n",
      "#######\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "best attrib is: 4\n",
      "best attrib is: 2\n",
      "['safety', {'low': 'unacc', 'med': ['persons', {'2': 'unacc', '4': ['buying', {'vhigh': ['lug_boot', {'small': 'unacc', 'med': ['doors', {'2': 'unacc', '3': 'unacc', '4': 'acc', '5more': ['maint', {'vhigh': 'unacc', 'high': 'unacc', 'med': 'unacc', 'low': 'acc'}]}], 'big': 'acc'}], 'high': 'unacc', 'med': 'acc', 'low': 'acc'}], 'more': 'unacc'}], 'high': 'unacc'}]\n",
      "\n",
      "IG-tree\n",
      "#######\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "best attrib is: 4\n",
      "best attrib is: 2\n",
      "['safety', {'low': 'unacc', 'med': ['persons', {'2': 'unacc', '4': ['buying', {'vhigh': ['lug_boot', {'small': 'unacc', 'med': ['doors', {'2': 'unacc', '3': 'unacc', '4': 'acc', '5more': ['maint', {'vhigh': 'unacc', 'high': 'unacc', 'med': 'unacc', 'low': 'acc'}]}], 'big': 'acc'}], 'high': 'unacc', 'med': 'acc', 'low': 'acc'}], 'more': 'unacc'}], 'high': 'unacc'}]\n",
      "\n",
      "ME-tree\n",
      "#######\n",
      "best attrib is: 0\n",
      "best attrib is: 2\n",
      "best attrib is: 1\n",
      "best attrib is: 4\n",
      "best attrib is: 3\n",
      "['buying', {'vhigh': ['doors', {'2': ['maint', {'vhigh': 'unacc', 'high': 'unacc', 'med': ['lug_boot', {'small': ['persons', {'2': 'unacc', '4': ['safety', {'low': 'acc', 'med': 'unacc', 'high': 'acc'}], 'more': 'unacc'}], 'med': 'unacc', 'big': 'acc'}], 'low': 'unacc'}], '3': 'unacc', '4': 'unacc', '5more': 'unacc'}], 'high': 'unacc', 'med': 'unacc', 'low': 'unacc'}]\n"
     ]
    }
   ],
   "source": [
    "# calculates the information gain\n",
    "def entropy_gain(S,Label_col_index, attrib_idx):\n",
    "    H_S = S.groupby(Label_col_index)[Label_col_index]\\\n",
    "    .apply(lambda x: (x.count()/S.shape[0])*np.log2(x.count()/S.shape[0]))\\\n",
    "    .sum()*-1\n",
    "    \n",
    "    Expected_H_Sv = S.groupby([attrib_idx,Label_col_index],as_index=False)[Label_col_index].count()\\\n",
    "    .groupby(attrib_idx).apply(lambda x:(x.sum()/S.shape[0])*((x/x.sum())*np.log2(x/x.sum()))).sum()*-1\n",
    "    return H_S - Expected_H_Sv[Label_col_index]\n",
    "\n",
    "\n",
    "# calculates the gini gain\n",
    "def gini_gain(S,Label_col_index, attrib_idx):\n",
    "    G_S = 1 - (S.groupby(Label_col_index)[Label_col_index]\\\n",
    "    .apply(lambda x: (x.count()/S.shape[0])**2)\\\n",
    "    .sum())\n",
    "    \n",
    "    Expected_G_Sv = 1 - (S.groupby([attrib_idx,Label_col_index],as_index=False)[Label_col_index].count()\\\n",
    "    .groupby(attrib_idx).apply(lambda x:(x.sum()/S.shape[0])*(x/x.sum())**2).sum())\n",
    "    return G_S - Expected_G_Sv[Label_col_index]\n",
    "    \n",
    "# calculates the majority error gain\n",
    "def ME_gain(S,Label_col_index, attrib_idx):  \n",
    "    freq = S.groupby(Label_col_index)[Label_col_index].count()\n",
    "    \n",
    "    ME_S = (freq.sum()- freq.max())/ S.shape[0]\n",
    "\n",
    "    Expected_ME_Sv = S.groupby([attrib_idx,Label_col_index],as_index=False)[Label_col_index].count()\\\n",
    "    .groupby(attrib_idx).apply(lambda x: (x.sum()/S.shape[0])*(1 - (x.max()/x.sum())))\\\n",
    "    .sum()\n",
    "    \n",
    "    return max(0,(ME_S - Expected_ME_Sv[Label_col_index]))\n",
    "\n",
    "# returns the column index of the best splitter attribute\n",
    "# S: set of examples\n",
    "# Attributes: list of attributes to be evaluated\n",
    "# splitter_algorithm: the splitter algorithm, can be one of the 3 values (\"ME\":Majority Error, \"GI\":Gini Index, \"EN\":Entropy)\n",
    "def Best_spliter_attribute(S, Attributes, Label_col_index, splitter_algorithm):\n",
    "    if len(Attributes) < 2:\n",
    "        return Attributes[0]\n",
    "    best_gain = 0\n",
    "    best_attribute = Attributes[0]\n",
    "    for v in Attributes:\n",
    "        if v != Label_col_index:\n",
    "            gain_v = 0\n",
    "            if splitter_algorithm == \"EN\":\n",
    "                gain_v = entropy_gain(S,Label_col_index, v)\n",
    "            elif splitter_algorithm == \"ME\":\n",
    "                gain_v = ME_gain(S,Label_col_index,v)\n",
    "            elif splitter_algorithm == \"GI\":\n",
    "                gain_v = gini_gain(S,Label_col_index,v)\n",
    "                \n",
    "            else:\n",
    "                assert False, \"Unknown splitter_algorithm:\" + splitter_algorithm + \"!!!\"\n",
    "            if gain_v > best_gain:\n",
    "                best_gain = gain_v\n",
    "                best_attribute = v\n",
    "    print(\"best attrib is:\",best_attribute)\n",
    "    return best_attribute\n",
    "\n",
    "attrib_name = {0:\"buying\", 1:\"maint\",2:\"doors\",3:\"persons\",4:\"lug_boot\",5:\"safety\"}\n",
    "label_values = [\"unacc\", \"acc\", \"good\", \"vgood\"]\n",
    "\n",
    "attrib_values = { \"buying\":   [\"vhigh\", \"high\", \"med\", \"low\"],\\\n",
    "                 \"maint\":    [\"vhigh\", \"high\", \"med\", \"low\"],\\\n",
    "                 \"doors\":    [\"2\", \"3\", \"4\", \"5more\"],\\\n",
    "                 \"persons\":  [\"2\", \"4\", \"more\"],\\\n",
    "                 \"lug_boot\": [\"small\", \"med\", \"big\"],\\\n",
    "                 \"safety\":   [\"low\", \"med\", \"high\"]\n",
    "                }\n",
    "\n",
    "def predict(root, entry):\n",
    "    example = {} \n",
    "    for i in range(6):\n",
    "        example[attrib_name[i]] = entry[i]\n",
    "    return predict_helper(root, example)\n",
    "\n",
    "def predict_helper(root, example):\n",
    "    root_attrib_name = root[0]\n",
    "    example_attrib_val = example[root_attrib_name]\n",
    "    if isinstance(root[1][example_attrib_val], list): # if attrib-node\n",
    "        return predict_helper(root[1][example_attrib_val], example)\n",
    "    else: # if leaf node\n",
    "        return root[1][example_attrib_val]\n",
    "    \n",
    "def predict_dataset(S, root, Label_col_index):\n",
    "    all = 0\n",
    "    correct = 0\n",
    "    for idx, row in S.iterrows():\n",
    "        all += 1\n",
    "        gold_label = row[Label_col_index]\n",
    "        predicted_label = predict(root, row)\n",
    "        if predicted_label == gold_label:\n",
    "            correct +=1\n",
    "    return correct / all # accuracy\n",
    "\n",
    "        \n",
    "        \n",
    "# ##############              ID3 implementation:\n",
    "# Input:\n",
    "# S: the set of Examples\n",
    "# Attributes: the set of measured attributes\n",
    "# Label_col_index: column index of the target attribute (the prediction)\n",
    "# max_tree_level: bounds the height of the tree\n",
    "# splitter_algorithm: can be one of the 3 values (\"ME\":Majority Error, \"GI\":Gini Index, \"EN\":Entropy)\n",
    "def ID3(S, Attributes, Label_col_index, max_tree_level, splitter_algorithm):\n",
    "    if(max_tree_level ==0):                                                             # if at max level\n",
    "        return S[Label_col_index].mode()[0]   \n",
    "    if S[Label_col_index].nunique() == 1:                                               # if all examples have same label:   \n",
    "        return S[Label_col_index].mode()[0]\n",
    "    elif len(Attributes) == 0:                                                          # if Attributes empty\n",
    "        return S[Label_col_index].mode()[0]\n",
    "    else:\n",
    "        # 1. Create a Root node for tree\n",
    "        Root = [] # each \"attribute node\" is a list s.t. \n",
    "                                                    # 1st element = string attribute name\n",
    "                                                    # 2nd element = dictionary children;\n",
    "                                                            # key = each possible attribute value v\n",
    "                                                            # value = an \"attribute node\" list;  or a string label for leaf nodes\n",
    "        # 2. A = attribute in Attributes that best splits S\n",
    "        A = Best_spliter_attribute(S, Attributes, Label_col_index, splitter_algorithm)\n",
    "        Root.append(attrib_name[A]) # 1st element = string attribute name\n",
    "        Root.append({})            # 2nd element = dictionary children;\n",
    "        # 3. for each possible value v of that A can take:\n",
    "        for v in attrib_values[attrib_name[A]]:\n",
    "            # 1. Add a new tree branch corresponding to A=v\n",
    "            # 2. Let Sv be the subset of examples in S with A=v\n",
    "            Sv = S.loc[S[A] == v]\n",
    "            if len(Sv) == 0:\n",
    "                Root[1][v] = S[Label_col_index].mode()[0] # string label\n",
    "            else:\n",
    "                Attrib_minus_A = Attributes\n",
    "                if len(Attrib_minus_A) > 0 and A in Attrib_minus_A:\n",
    "                    Attrib_minus_A.remove(A)\n",
    "                Root[1][v] = ID3(Sv, Attrib_minus_A,Label_col_index, max_tree_level-1,splitter_algorithm) # an \"attribute node\" list;\n",
    "        return Root\n",
    "        \n",
    "# ##############              main\n",
    "print(\"Training ...\")\n",
    "print(\"gini-tree\")\n",
    "print(\"#######\")\n",
    "Attributes = [0,1,2,3,4,5] # initially put all attributes except the label in Attributes set\n",
    "tree_gini = ID3(test_df, Attributes,6, 6, \"GI\")\n",
    "print(tree_gini)\n",
    "\n",
    "print(\"\\nIG-tree\")\n",
    "print(\"#######\")\n",
    "Attributes = [0,1,2,3,4,5] # initially put all attributes except the label in Attributes set\n",
    "tree_entopy = ID3(test_df, Attributes,6, 10, \"EN\")\n",
    "print(tree_entopy)\n",
    "\n",
    "print(\"\\nME-tree\")\n",
    "print(\"#######\")\n",
    "Attributes = [0,1,2,3,4,5] # initially put all attributes except the label in Attributes set\n",
    "tree_ME = ID3(test_df, Attributes,6, 10, \"ME\")\n",
    "print(tree_ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree hight: 1\n",
      "gain approach: EN\n",
      "best attrib is: 5\n",
      "train accuracy: 0.698\n",
      "test accuracy:  0.7032967032967034\n",
      "###############\n",
      "gain approach: GI\n",
      "best attrib is: 5\n",
      "train accuracy: 0.698\n",
      "test accuracy:  0.7032967032967034\n",
      "###############\n",
      "gain approach: ME\n",
      "best attrib is: 0\n",
      "train accuracy: 0.698\n",
      "test accuracy:  0.7032967032967034\n",
      "###############\n",
      "tree hight: 2\n",
      "gain approach: EN\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "train accuracy: 0.69\n",
      "test accuracy:  0.7142857142857143\n",
      "###############\n",
      "gain approach: GI\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "train accuracy: 0.69\n",
      "test accuracy:  0.7142857142857143\n",
      "###############\n",
      "gain approach: ME\n",
      "best attrib is: 0\n",
      "best attrib is: 2\n",
      "best attrib is: 5\n",
      "best attrib is: 1\n",
      "best attrib is: 3\n",
      "train accuracy: 0.684\n",
      "test accuracy:  0.7142857142857143\n",
      "###############\n",
      "tree hight: 3\n",
      "gain approach: EN\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "best attrib is: 4\n",
      "best attrib is: 1\n",
      "train accuracy: 0.747\n",
      "test accuracy:  0.75\n",
      "###############\n",
      "gain approach: GI\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "best attrib is: 4\n",
      "best attrib is: 1\n",
      "train accuracy: 0.747\n",
      "test accuracy:  0.75\n",
      "###############\n",
      "gain approach: ME\n",
      "best attrib is: 0\n",
      "best attrib is: 2\n",
      "best attrib is: 1\n",
      "best attrib is: 3\n",
      "best attrib is: 4\n",
      "train accuracy: 0.698\n",
      "test accuracy:  0.7032967032967034\n",
      "###############\n",
      "tree hight: 4\n",
      "gain approach: EN\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "best attrib is: 4\n",
      "best attrib is: 1\n",
      "train accuracy: 0.725\n",
      "test accuracy:  0.7239010989010989\n",
      "###############\n",
      "gain approach: GI\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "best attrib is: 4\n",
      "best attrib is: 1\n",
      "train accuracy: 0.725\n",
      "test accuracy:  0.7239010989010989\n",
      "###############\n",
      "gain approach: ME\n",
      "best attrib is: 0\n",
      "best attrib is: 2\n",
      "best attrib is: 1\n",
      "best attrib is: 4\n",
      "best attrib is: 5\n",
      "train accuracy: 0.696\n",
      "test accuracy:  0.7060439560439561\n",
      "###############\n",
      "tree hight: 5\n",
      "gain approach: EN\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "best attrib is: 4\n",
      "best attrib is: 2\n",
      "train accuracy: 0.73\n",
      "test accuracy:  0.728021978021978\n",
      "###############\n",
      "gain approach: GI\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "best attrib is: 4\n",
      "best attrib is: 2\n",
      "train accuracy: 0.73\n",
      "test accuracy:  0.728021978021978\n",
      "###############\n",
      "gain approach: ME\n",
      "best attrib is: 0\n",
      "best attrib is: 2\n",
      "best attrib is: 1\n",
      "best attrib is: 4\n",
      "best attrib is: 3\n",
      "train accuracy: 0.695\n",
      "test accuracy:  0.7060439560439561\n",
      "###############\n",
      "tree hight: 6\n",
      "gain approach: EN\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "best attrib is: 4\n",
      "best attrib is: 2\n",
      "train accuracy: 0.724\n",
      "test accuracy:  0.7266483516483516\n",
      "###############\n",
      "gain approach: GI\n",
      "best attrib is: 5\n",
      "best attrib is: 3\n",
      "best attrib is: 0\n",
      "best attrib is: 4\n",
      "best attrib is: 2\n",
      "train accuracy: 0.724\n",
      "test accuracy:  0.7266483516483516\n",
      "###############\n",
      "gain approach: ME\n",
      "best attrib is: 0\n",
      "best attrib is: 2\n",
      "best attrib is: 1\n",
      "best attrib is: 4\n",
      "best attrib is: 3\n",
      "train accuracy: 0.695\n",
      "test accuracy:  0.7060439560439561\n",
      "###############\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nPrediction...\")\n",
    "for hight in range(1,7):\n",
    "    print(\"tree hight:\", hight)\n",
    "    for app in [\"EN\", \"GI\", \"ME\"]:\n",
    "        print(\"gain approach:\", app)\n",
    "        Attributes = [0,1,2,3,4,5] # initially put all attributes except the label in Attributes set\n",
    "        tree = ID3(test_df, Attributes,6, hight, app)\n",
    "#         print(\"tree:\")\n",
    "#         print(tree)\n",
    "        print(\"train accuracy:\",predict_dataset(train_df, tree,6))\n",
    "        print(\"test accuracy: \", predict_dataset(test_df, tree,6))\n",
    "        print(\"###############\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
